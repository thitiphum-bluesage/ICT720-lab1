{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        _id   device_id  temp_start  humi_start  target_temp  \\\n",
      "0  6637de928828c818b21efc28  ou_bedroom   30.550724   57.054836           30   \n",
      "1  6637e8af8828c818b21efc32  ou_bedroom   30.400000   61.529984           30   \n",
      "2  6637ed408828c818b21efc3a  ou_bedroom   31.700001   61.426476           30   \n",
      "3  6637f0217cf1520579764f26  ou_bedroom   32.133331   53.228130           30   \n",
      "4  6637fe597cf1520579764f2a  ou_bedroom   37.879707   48.116722           30   \n",
      "\n",
      "   time_use  time_start   humi_end  __v  \n",
      "0      1342  1714936147  50.138153    0  \n",
      "1       150  1714939929  60.726280    0  \n",
      "2       561  1714940687  57.063969    0  \n",
      "3       380  1714941605  54.241890    0  \n",
      "4       891  1714944734  52.266129    0  \n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Fetch the data\n",
    "url = \"http://62.72.58.117:3000/training-cycles/ou_bedroom\"\n",
    "response = requests.get(url)\n",
    "data = response.json()\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Cleaning\n",
    "# Drop columns that are not required for modeling\n",
    "df_cleaned = df.drop(['_id', 'device_id', '__v'], axis=1)\n",
    "\n",
    "# Convert Unix timestamp to seconds since the first record (for simplicity)\n",
    "min_time = df_cleaned['time_start'].min()\n",
    "df_cleaned['time_start'] = df_cleaned['time_start'] - min_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   temp_start  humi_start  target_temp  time_use  time_start   humi_end\n",
      "0   30.550724   57.054836           30      1342           0  50.138153\n",
      "1   30.400000   61.529984           30       150        3782  60.726280\n",
      "2   31.700001   61.426476           30       561        4540  57.063969\n",
      "3   32.133331   53.228130           30       380        5458  54.241890\n",
      "4   37.879707   48.116722           30       891        8587  52.266129\n",
      "5   32.265217   53.578228           30       570       11882  53.727398\n"
     ]
    }
   ],
   "source": [
    "print(df_cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "temp_start     0\n",
      "humi_start     0\n",
      "target_temp    0\n",
      "time_use       0\n",
      "time_start     0\n",
      "humi_end       0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df_cleaned.isnull().sum()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean MSE from cross-validation: 742139.3940230227\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-7 {color: black;}#sk-container-id-7 pre{padding: 0;}#sk-container-id-7 div.sk-toggleable {background-color: white;}#sk-container-id-7 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-7 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-7 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-7 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-7 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-7 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-7 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-7 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-7 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-7 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-7 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-7 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-7 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-7 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-7 div.sk-item {position: relative;z-index: 1;}#sk-container-id-7 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-7 div.sk-item::before, #sk-container-id-7 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-7 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-7 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-7 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-7 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-7 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-7 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-7 div.sk-label-container {text-align: center;}#sk-container-id-7 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-7 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-7\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;minmaxscaler&#x27;, MinMaxScaler()),\n",
       "                (&#x27;linearregression&#x27;, LinearRegression())])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-11\" type=\"checkbox\" ><label for=\"sk-estimator-id-11\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;minmaxscaler&#x27;, MinMaxScaler()),\n",
       "                (&#x27;linearregression&#x27;, LinearRegression())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-12\" type=\"checkbox\" ><label for=\"sk-estimator-id-12\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MinMaxScaler</label><div class=\"sk-toggleable__content\"><pre>MinMaxScaler()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-13\" type=\"checkbox\" ><label for=\"sk-estimator-id-13\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearRegression</label><div class=\"sk-toggleable__content\"><pre>LinearRegression()</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('minmaxscaler', MinMaxScaler()),\n",
       "                ('linearregression', LinearRegression())])"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.pipeline import make_pipeline\n",
    "import numpy as np\n",
    "\n",
    "# Data Preparation\n",
    "X = df[['temp_start', 'humi_start', 'target_temp']]  # Updated feature set\n",
    "y = df['time_use']\n",
    "# Normalize features\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Setup the model with normalization\n",
    "model = make_pipeline(scaler, LinearRegression())\n",
    "\n",
    "# Use cross-validation to evaluate the model\n",
    "scores = cross_val_score(model, X, y, cv=5, scoring='neg_mean_squared_error')\n",
    "mean_mse = np.mean(scores) * -1\n",
    "print(f'Mean MSE from cross-validation: {mean_mse}')\n",
    "\n",
    "model.fit(X, y)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted time used: 690.6427170745217 seconds\n"
     ]
    }
   ],
   "source": [
    "example = pd.DataFrame({\n",
    "    'temp_start': [32],   # Current temperature\n",
    "    'humi_start': [55],   # Current humidity\n",
    "    'target_temp': [30]   # Target temperature\n",
    "})\n",
    "predicted_time = model.predict(example)\n",
    "print(f\"Predicted time used: {max(0, predicted_time[0])} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model type before saving: <class 'sklearn.pipeline.Pipeline'>\n",
      "Model type after loading: <class 'sklearn.pipeline.Pipeline'>\n",
      "Sample prediction: [690.64271707]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\thiti\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:465: UserWarning: X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Assuming 'model' is your trained model object\n",
    "print(\"Model type before saving:\", type(model))\n",
    "\n",
    "# Now save the model\n",
    "import joblib\n",
    "joblib.dump(model, 'trained_model.pkl')\n",
    "\n",
    "# Load the model again to test\n",
    "model = joblib.load('trained_model.pkl')\n",
    "print(\"Model type after loading:\", type(model))\n",
    "\n",
    "# Test prediction\n",
    "sample_data = np.array([[32, 55, 30]])\n",
    "print(\"Sample prediction:\", model.predict(sample_data))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['trained_model.pkl']"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "# Save the trained model\n",
    "joblib.dump(model, 'trained_model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted time for temp_start = 30°C, humi_start = 55%, target_temp = 30°C: 739.8337507597817 seconds\n",
      "Predicted time for temp_start = 32°C, humi_start = 55%, target_temp = 30°C: 690.6427170745217 seconds\n",
      "Predicted time for temp_start = 35°C, humi_start = 55%, target_temp = 30°C: 616.8561665466316 seconds\n",
      "Predicted time for temp_start = 37°C, humi_start = 55%, target_temp = 30°C: 567.6651328613716 seconds\n",
      "Predicted time for temp_start = 40°C, humi_start = 55%, target_temp = 30°C: 493.8785823334814 seconds\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Define different starting temperatures to see their effect on cooling time\n",
    "temperatures = [30, 32, 35, 37, 40]  # Example temperatures in degrees Celsius\n",
    "humidity = 55  # Constant humidity for simplicity\n",
    "target_temp = 30  # Constant target temperature\n",
    "\n",
    "results = []\n",
    "\n",
    "# Load the model (ensure it's loaded correctly as shown in previous steps)\n",
    "loaded_model = joblib.load('trained_model.pkl')\n",
    "\n",
    "for temp in temperatures:\n",
    "    example = pd.DataFrame({\n",
    "        'temp_start': [temp],\n",
    "        'humi_start': [humidity],\n",
    "        'target_temp': [target_temp]\n",
    "    })\n",
    "    predicted_time = loaded_model.predict(example)\n",
    "    results.append({\n",
    "        'temp_start': temp,\n",
    "        'predicted_time': max(0, predicted_time[0])  # Ensure no negative times\n",
    "    })\n",
    "\n",
    "# Display the results\n",
    "for result in results:\n",
    "    print(f\"Predicted time for temp_start = {result['temp_start']}°C, humi_start = {humidity}%, target_temp = {target_temp}°C: {result['predicted_time']} seconds\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
